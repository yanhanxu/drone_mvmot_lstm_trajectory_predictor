ðŸ“† Project Highlights

âœ… Multi-view object detection and tracking

â™»ï¸ Cross-view ID matching and merging

ðŸ§  Transformer-based feature enhancement

ðŸ‘¤ ReID-based feature fusion for identity association

ðŸ”® LSTM-based trajectory prediction (ADE/FDE metrics)

ðŸ“Š Visualization of prediction errors (histogram, curves, ADE/FDE examples)

ðŸ“ Project Structure

drone_mvmot_lstm_trajectory_predictor/
â”œâ”€â”€ demo/                                # Main scripts and visualizations
â”‚   â”œâ”€â”€ your_main_script.py              # Main execution script
â”‚   â”œâ”€â”€ prediction_picture/              # Visualized prediction errors
â”‚   â””â”€â”€ configs/                         # mmtrack config files
â”‚
â”œâ”€â”€ data/                                # Dataset
â”‚   â””â”€â”€ MDMT/                            # Multi-drone multi-target dataset
â”‚       â”œâ”€â”€ test/                        # Image sequences
â”‚       â””â”€â”€ new_xml/                     # Ground-truth trajectory (CVAT XML)
â”‚
â”œâ”€â”€ checkpoint/                          # Model weights
â”‚   â””â”€â”€ transreid/
â”‚       â””â”€â”€ deit_transreid.pth
â”‚
â”œâ”€â”€ result/                              # Tracking results and logs
â”œâ”€â”€ requirements.txt                     # Python dependencies
â””â”€â”€ README.md                            # This file

ðŸ› ï¸ Environment Setup

Recommended: Python 3.8, PyTorch 1.7+, Anaconda preferred.

Install Dependencies

pip install -r requirements.txt

Sample requirements.txt:

torch>=1.7.0
torchvision
mmcv-full==1.5.0
mmdet==2.25.1
mmtrack==0.12.0
opencv-python
numpy
matplotlib
scipy
Pillow

ðŸš€ Quick Start

1. Prepare Dataset[MDMT Datasets](https://github.com/VisDrone/Multi-Drone-Multi-Object-Detection-and-Tracking)


Place your image sequences and annotation files:

data/MDMT/test/       # Sequence images (e.g., 1-1, 1-2)
data/MDMT/new_xml/    # Ground truth XMLs

how to download mmtrackingï¼š[MMtrack](https://github.com/open-mmlab/mmtracking/blob/master/docs/en/install.md)

2. Prepare Models

Download:

LSTM model checkpoint (e.g., checkpoint_epoch30_lstm.pth)

ReID model (e.g., deit_transreid.pth)

Place them in the checkpoint/ directory and update the script paths accordingly.

3. Run the Pipeline

python demo/your_main_script.py \
  --config demo/configs/mot/bytetrack/swin_transformer_bytetrack_Adam.py \
  --input data/MDMT/test/1/ \
  --xml_dir data/MDMT/new_xml/1/ \
  --lstm-checkpoint ./checkpoint/lstm/checkpoint_epoch30_lstm.pth \
  --output ./result/outputA.mp4 \
  --output2 ./result/outputB.mp4 \
  --device cuda:0

ðŸ“ˆ Visual Outputs
<img width="189" alt="image" src="https://github.com/user-attachments/assets/cabc197b-8ea4-4259-b42f-0a6d06756581" />
<img width="189" alt="image" src="https://github.com/user-attachments/assets/33ad8cad-39b3-45cb-a3b5-d8e63cf303d2" />
<img width="189" alt="image" src="https://github.com/user-attachments/assets/88bc4967-2eb5-4fc2-aadd-2b2235ee6eee" />
<img width="189" alt="image" src="https://github.com/user-attachments/assets/deb9cea5-b8a8-4566-81e5-97364b7f213c" />



Prediction results and error analysis will be saved to:

demo/prediction_picture/

Includes:

Average / Max / Median prediction errors

ADE / FDE visual examples

Histogram of all prediction errors

Error trend over frames

(Optional) Per-object error curves

ðŸ“Š Metrics Explained

Metric

Description

ADE

Average Displacement Error (average distance over all predicted steps)

FDE

Final Displacement Error (distance of final predicted step)

Max Error

Maximum point-wise prediction error

Error Histogram

Distribution of prediction errors

ðŸ“† Example Args

python your_main_script.py --show --fps 10 --backend cv2

ðŸ“„ Recommended .gitignore

*.pth
*.mp4
*.avi
*.npy
*.json
*.log
*.csv
result/
demo/prediction_picture/

ðŸ““ License

This project is licensed under the MIT License. Model weights are for research only.

ðŸ™Œ Acknowledgements

Built upon and inspired by:

mmtracking

ByteTrack

TransReID

For questions, issues or pull requests, feel free to contribute
